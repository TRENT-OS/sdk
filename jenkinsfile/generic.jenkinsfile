//------------------------------------------------------------------------------
//
// Generic Jenkins Pipeline Script
//
// Copyright (C) 2020-2021, HENSOLDT Cyber GmbH
//
//------------------------------------------------------------------------------
//
// Job parameters (must be configured in the Jenkins job, otherwise we do not
// see them here as global variables):
//
//    PLATFORM
//    BRANCH_OR_COMMIT
//    FLAGS (NOTE: Passed as String, convert to Integer for evaluation.)
//    TEST_SYSTEM
//    BUILD_PARAMS
//    TEST_SCRIPT
//    TEST_PARAMS
//    UPSTREAM_JOB_NAME
//    UPSTREAM_JOB_ID

params.each { println(it.key + " = " + it.value) }


// Global variables defined with 'def' cannot be accessed in methods due to
// different scoping. Without 'def', they can be accessed - however, that is bad
// practice. Using 'def' and the '@groovy.transform.Field' annotation is the
// best option. For details see https://stackoverflow.com/questions/50571316

@groovy.transform.Field
def final NODE_LABEL_CONTROL = 'pipeline-control'

@groovy.transform.Field
def final NODE_LABEL_BUILD = 'build'

@groovy.transform.Field
def final NODE_LABEL_TEST = 'test'

// Flag used in the control pipeline to identify SDK demos.
@groovy.transform.Field
def final FLAG_SDK_DEMO = 1 << 2

@groovy.transform.Field
def final SDK_PACKAGE = 'sdk-package.tar.bz2'

@groovy.transform.Field
def final DEV_SDK_PACKAGE = 'dev-sdk-package.tar.bz2'

@groovy.transform.Field
def final SYSTEM_PACKAGE = 'system-package.tar.bz2'

@groovy.transform.Field
def final SDK_DIR = 'src/sdk'

@groovy.transform.Field
def final TESTS_DIR = 'src/tests'

@groovy.transform.Field
def final TEST_COMMON_DIR = 'src/test-common'

@groovy.transform.Field
def final STASH_TEST_PACKAGE = 'test_package'



// SYSTEM_DIR holds the path to the current system under test:
// - For SDK demos - with the SDK demo flag set - TEST_SYSTEM specifies the demo
//   path relative within SDK_DIR and SYSTEM_DIR will be updated accordingly in
//   'get_sdk_and_system()'.
// - Otherwise TEST_SYSTEM specifies a repo that will be checked out into the
//   default path of SYSTEM_DIR in 'get_sdk_and_system()'.
@groovy.transform.Field
def SYSTEM_DIR = ''


//------------------------------------------------------------------------------
// Docker
//------------------------------------------------------------------------------
//
// Notes:
// * bind the localtime to docker container to avoid problems of gaps between
//   the localtime of the container and the host.
// * add user to group "stack" (1001) in order to grant usage of Haskell stack
//   in the docker image
//
// ToDo
// * why are sudo right needed in the test container
//

def DOCKER_BASE = 'hc-docker:5000'
def DOCKER_REGISTRY = 'https://' + DOCKER_BASE

def DOCKER_BUILD_ENV = [
    registry: DOCKER_REGISTRY,
    image:    DOCKER_BASE + '/trentos_build:20210503',
    args:     ['-v /etc/localtime:/etc/localtime:ro',
               '--group-add=stack',
               '--group-add=sudo'
              ].join(' ')
]

def DOCKER_TEST_ENV  = [
    registry: DOCKER_REGISTRY,
    image:    DOCKER_BASE + '/trentos_test:20211217',
    args:     ['-v /home/jenkins/.ssh/:/home/jenkins/.ssh:ro',
               '-v /etc/localtime:/etc/localtime:ro',
               '--network=bridge',
               '--cap-add=NET_ADMIN',
               '--cap-add=NET_RAW',
               '--device=/dev/net/tun',
               '--group-add=sudo'
              ].join(' ')
]


//------------------------------------------------------------------------------
def set_build_info()
{
    currentBuild.displayName = BRANCH_OR_COMMIT + ', ' +
                               TEST_SYSTEM + ', ' +
                               PLATFORM +
                               ' [build' +
                               (TEST_SCRIPT ? '+test' : '') +
                               ((FLAGS.toInteger() & FLAG_SDK_DEMO) ? '+demo' : '') +
                               ']'

    manager.createSummary("text.gif").appendText(
        '<table style="border: 1px solid black; border-collapse: collapse;">'+
            params.collect { param ->
                '<tr>'+
                    '<td style="border: 1px solid black">'+
                        '<b><code>'+param.key+'</code></b>'+
                    '</td>'+
                    '<td style="border: 1px solid black">'+
                        (param.value?:'<i>(null)</i>')+
                    '</td>'+
                '</tr>'
            }.join('') +
        '</table>'
    )
}


//------------------------------------------------------------------------------
def do_notify_bitbucket()
{
    // the StashNotifier requires to run in a node block, which should not be
    // necessary technically. See also the open issue issue at
    // https://github.com/jenkinsci/stashnotifier-plugin/issues/234

    if (env.NODE_NAME)
    {
        notifyBitbucket()
    }
    else
    {
        // If we don't specify any node here explicitly, it will not run on the
        // master node even if it is free, because the master is reserved
        // exclusively for bound jobs. If all other executors are busy, the
        // whole job will stuck just for sending a notification. Thus we use the
        // master node for the notification.
        node(label: NODE_LABEL_CONTROL) { notifyBitbucket() }
    }
}


//------------------------------------------------------------------------------
def run_app(
    application,
    param_array = null
) {
    def cmdLine = application

    if (param_array)
    {
        cmdLine += ' ' + param_array.join(' ')
    }

    try
    {
        sh(cmdLine)
    }
    catch (Exception e)
    {
        println('Exception running command: ' + e)
        throw e
    }
}


//------------------------------------------------------------------------------
def run_shell_script(
    script,
    param_array = null
) {
    run_app(script, param_array)
}


//------------------------------------------------------------------------------
def run_python_package(
    python_params,
    python_paths,
    python_package, // can't use 'package', it's a reserved groovy keyword
    package_params = []
) {
    def env = []
    def params = []

    if (python_paths)
    {
       env += ['PYTHONPATH=' + python_paths.join(':')]
    }

    if (python_params)
    {
        params += python_params
    }

    params += ['-m', python_package]

    if (package_params)
    {
        params += package_params
    }

    withEnv(env)
    {
        run_app('python3', params)
    }
}


//------------------------------------------------------------------------------
def do_git_checkout(
    repo,
    branch,
    folder = NULL
) {
    println(
        'checkout: ' + repo + '@' + branch +
        ( folder ? (' into ' + folder) : '' ) +
        ' ...'
    )

    try
    {
        def scm_cfg = scm.userRemoteConfigs[0]

        // use project URL to build repo URL
        def m = (scm_cfg.url =~ '(.*)://([^/]*)(?:/(.*))?')
        if (!m.matches()) {
            throw new Exception('could not parse url: ' + url)
        }
        def repo_url = m.group(1) + '://' + m.group(2) + '/' + repo + '.git'

        def scmVars = checkout([
                    poll: false,
                    changelog: false,
                    scm: [
                        $class: 'GitSCM',
                        branches: [
                            [name: branch]
                        ],
                        doGenerateSubmoduleConfigurations: false,
                        extensions: [
                            [
                                $class: 'RelativeTargetDirectory',
                                relativeTargetDir: (folder ? folder : '.')
                            ],

                            [
                                $class: 'SubmoduleOption',
                                disableSubmodules: false,
                                recursiveSubmodules: true,
                                trackingSubmodules: false,
                                parentCredentials: true,
                                // parallel checkouts speed up things, but too
                                // many threads (from too man parallel jobs)
                                // will eventually overload the GIT server and
                                // we get failures due to timeouts. We've seen
                                // this happening with 8 threads, so try 4 now.
                                threads: 4
                            ]
                        ],
                        userRemoteConfigs: [
                            [
                                credentialsId: scm_cfg.credentialsId,
                                url: repo_url
                            ]
                        ]
                    ]
                ])

        // delete additional folder that is created by the checkout
        if (folder) { run_app('rmdir', [folder+'@tmp']) }

        return scmVars
    }
    catch (Exception e)
    {
        println('Exception: ' + e)
        return null
    }
}


//------------------------------------------------------------------------------
def do_checkout(
    repo,
    branch,
    dir = '.'
) {
    manager.createSummary("text.gif").appendText('<hr>' + repo)

    def scmVars = do_git_checkout(repo, branch, dir)

    // if this is a custom branch, then fall back to integration
    if ( (!scmVars) && ( !(branch in ['integration', 'master']) ) )
    {
        manager.createSummary("text.gif").appendText('no branch: ' + branch)
        scmVars = do_git_checkout(repo, 'integration', dir)
    }

    if (!scmVars)
    {
        error('checkout error for: ' + branch + '@' + repo)
    }
}


//------------------------------------------------------------------------------
def get_sdk(
    package_name
) {

    // This only works in production mode if the job did also call
    // copyArtifactPermission() to give us the permission to copy artifacts.
    copyArtifacts(
        projectName: UPSTREAM_JOB_NAME,
        selector: specific("${UPSTREAM_JOB_ID}"), // need to ensure this is a string
        filter: package_name,
    )

    run_app('mkdir', ['-p', SDK_DIR])
    run_app('tar', ['-xf ' + package_name, '-C ' + SDK_DIR])
}


//------------------------------------------------------------------------------
def get_sdk_and_system()
{
    if (FLAGS.toInteger() & FLAG_SDK_DEMO)
    {
        // Build against SDK package
        get_sdk(SDK_PACKAGE)

        // Build from SDK package
        SYSTEM_DIR = SDK_DIR + '/' + TEST_SYSTEM
    }
    else
    {
        // Build against dev SDK package
        get_sdk(DEV_SDK_PACKAGE)

        SYSTEM_DIR = 'src/system'

        // Build from repo
        do_checkout(
            TEST_SYSTEM,
            BRANCH_OR_COMMIT,
            SYSTEM_DIR)
    }
}


//------------------------------------------------------------------------------
def save_current_job_log(
    name
) {
    // Get the current job's log up to now. One day we should find a nicer way
    // for this than downloading it, because that requires read access for
    // anonymous users to the Jenkins GUI. Accessing the log though the builds's
    // RunWrapper object is not possible, because nothing is exposed there. The
    // only option would be via rawBuild(), but this method must be whitelisted
    // for usage in groovy pipelines then.

    run_app(
        'wget',
        [
            '-q',
            '--no-check-certificate',
            '-O ' + name, // make wget overwrite file if it already exists
            BUILD_URL + 'consoleText'
        ]
    )
}


//------------------------------------------------------------------------------
def print_step_info(
    name
) {
    println('#################### ' + name)
}


//------------------------------------------------------------------------------
//------------------------------------------------------------------------------
//------------------------------------------------------------------------------
pipeline {

    agent none

    options {
        skipDefaultCheckout()
    }

    stages {

        //----------------------------------------------------------------------
        stage('Init') {
            steps {
                set_build_info()
            }
        }

        //----------------------------------------------------------------------
        stage('Build Stage') {

            agent { label NODE_LABEL_BUILD }

            stages {

                //--------------------------------------------------------------
                stage('checkout') {
                    steps {
                        print_step_info(env.STAGE_NAME)
                        cleanWs()
                        get_sdk_and_system()
                        do_notify_bitbucket()
                    }
                }

                //--------------------------------------------------------------
                stage('build') {
                    agent {
                        docker {
                            reuseNode true
                            alwaysPull true
                            registryUrl DOCKER_BUILD_ENV.registry
                            image DOCKER_BUILD_ENV.image
                            args DOCKER_BUILD_ENV.args
                        }
                    }
                    steps {
                        print_step_info(env.STAGE_NAME)

                        run_shell_script(
                            SDK_DIR+'/build-system.sh',
                            [
                                SYSTEM_DIR,
                                PLATFORM,
                                'build', // build output
                                '-D CMAKE_BUILD_TYPE=Debug',
                                BUILD_PARAMS
                            ]
                        )
                    }
                }

                //--------------------------------------------------------------
                stage('static_analyzer') {
                    agent {
                        docker {
                            reuseNode true
                            alwaysPull true
                            registryUrl DOCKER_BUILD_ENV.registry
                            image DOCKER_BUILD_ENV.image
                            args DOCKER_BUILD_ENV.args
                        }
                    }
                    steps {
                        print_step_info(env.STAGE_NAME)

                        do_checkout(
                            'ta/seos_tests',
                            BRANCH_OR_COMMIT,
                            TESTS_DIR)

                        // Continue with the test run even on static analyzer
                        // errors, but mark the stage and the build as failed
                        // even if the tests are successful.
                        catchError(buildResult: 'FAILURE', stageResult: 'FAILURE') {
                            run_shell_script(
                                TESTS_DIR+'/cppcheck/check_static_analyzer.sh',
                                [
                                    'build/compile_commands.json',
                                    SDK_DIR
                                ]
                            )
                        }
                    }
                }

                //--------------------------------------------------------------
                stage('package_build_result') {
                    steps {
                        print_step_info(env.STAGE_NAME)

                        save_current_job_log('build.log')

                        run_app('tar', [
                            '--ignore-failed-read',
                            '-cjf ' + SYSTEM_PACKAGE,

                            // NOTE: Uncomment the following line in case the
                            //       whole build folder should be stored.
                            // 'build/*',

                            // Store the following artifacts. The image will be
                            // required in the test stage (if tests enabled).
                            'build/images/os_image.elf',
                            'build/os_system/graph.svg',
                            'build/compile_commands.json',
                            'build.log'
                        ])
                    }
                }

                //--------------------------------------------------------------
                stage('archive_build') {
                    // If we are building only, but not testing, we are done in
                    // the pipeline here. Publish the build package.
                    when { expression { TEST_SCRIPT == '' } }
                    steps {
                        print_step_info(env.STAGE_NAME)
                        archiveArtifacts(
                            artifacts: SYSTEM_PACKAGE,
                            fingerprint: true
                        )
                    }
                }

                //--------------------------------------------------------------
                stage('stash') {
                    // If we are testing the build artifacts now, stash it
                    // together with the system sources, so the test node can
                    // retrieve it.
                    when { expression { TEST_SCRIPT != '' } }
                    steps {
                        print_step_info(env.STAGE_NAME)
                        stash(
                            name: STASH_TEST_PACKAGE,
                            includes: [
                                SYSTEM_PACKAGE,
                                SYSTEM_DIR+'/'
                            ].join(',')
                        )
                    }
                }

                //--------------------------------------------------------------
                stage('cleanup') {
                    steps {
                        print_step_info(env.STAGE_NAME)
                        cleanWs()
                    }
                }

            }
        }

        //----------------------------------------------------------------------
        stage('Test Stage') {

            when {
                beforeAgent true
                expression { TEST_SCRIPT != '' }
            }

            agent { label NODE_LABEL_TEST }

            stages {

                //--------------------------------------------------------------
                stage('checkout') {
                    steps {
                        print_step_info(env.STAGE_NAME)

                        cleanWs()

                        unstash(STASH_TEST_PACKAGE)
                        run_app('tar', ['-xf ' + SYSTEM_PACKAGE])

                        get_sdk(DEV_SDK_PACKAGE)

                        do_checkout(
                            'ta/common',
                            BRANCH_OR_COMMIT,
                            TEST_COMMON_DIR)

                        do_checkout(
                            'ta/seos_tests',
                            BRANCH_OR_COMMIT,
                            TESTS_DIR)
                    }
                }

                //--------------------------------------------------------------
                stage('test_doc') {
                    agent {
                        docker {
                            reuseNode true
                            alwaysPull true
                            registryUrl DOCKER_TEST_ENV.registry
                            image DOCKER_TEST_ENV.image
                            args DOCKER_TEST_ENV.args
                        }
                    }
                    steps {
                        catchError(buildResult: 'UNSTABLE', stageResult: 'FAILURE')
                        {
                            dir('test-doc')
                            {
                                run_python_package(
                                    ['-B',],
                                    ['../'+TEST_COMMON_DIR, '../'+TESTS_DIR],
                                    'pydoc',
                                    ['-w', '../'+TESTS_DIR+'/'+TEST_SCRIPT] )
                            }
                        }
                    }
                }

                //--------------------------------------------------------------
                stage('test') {
                    options {
                        // Limit the time the test can run. This also catches
                        // the cases where the (buggy) test framework doesn't
                        // kill all threads and these threads keep it from
                        // terminating. The longest test execution time seen
                        // so far was 310 seconds for test_uart, so double of
                        // that looks like a good value to use for now.
                        timeout(time: 620, unit: 'SECONDS')
                    }

                    agent {
                        docker {
                            reuseNode true
                            alwaysPull true
                            registryUrl DOCKER_TEST_ENV.registry
                            image DOCKER_TEST_ENV.image
                            args DOCKER_TEST_ENV.args
                        }
                    }

                    steps {
                        print_step_info(env.STAGE_NAME)

                        catchError(buildResult: 'UNSTABLE', stageResult: 'FAILURE')
                        {
                            dir('test-logs')
                            {
                                script
                                {
                                    def prepareTestSystem = '../'+SYSTEM_DIR+'/prepare_test.sh'
                                    if (fileExists(prepareTestSystem))
                                    {
                                        run_shell_script(
                                            prepareTestSystem,
                                            ['../'+SDK_DIR])
                                    }
                                }

                                run_python_package(
                                    ['-B',],
                                    ['../'+TEST_COMMON_DIR, '../'+TESTS_DIR],
                                    'pytest',
                                    [
                                        // pytest options
                                        '-p', 'no:cacheprovider',
                                        '-v', // verbose output
                                        '-o log_cli=True', // write logs to console
                                        '--capture=no', // show printf() from python scripts in console
                                        '--tb=short', // control traceback (long, short, line, native, no)
                                        // test framework options
                                        '--print_logs', // print system logs in console
                                        '--proxy=../'+SDK_DIR+'/bin/proxy_app,TCP',
                                        '--target=' + PLATFORM,
                                        '--system_image=../build/images/os_image.elf',
                                        '--resource_dir=../'+SDK_DIR+'/resources',
                                        '--junitxml=../test_results.xml',
                                        '--tc-file=../'+TESTS_DIR+'/platform_config/default.ini',
                                        '--tc-file=../'+TESTS_DIR+'/platform_config/' + PLATFORM + '.ini',
                                        TEST_PARAMS,
                                        '../'+TESTS_DIR+'/'+TEST_SCRIPT
                                    ]
                                )
                            }
                        }
                    }
                }

                //--------------------------------------------------------------
                stage('archive_build_and_tests') {

                    steps {
                        print_step_info(env.STAGE_NAME)

                        save_current_job_log('build_and_test.log')

                        run_app(
                            'tar',
                            [
                                '--ignore-failed-read',
                                '-cjf ' + SYSTEM_PACKAGE,
                                'build/',
                                'build_and_test.log',
                                'test-doc/',
                                'test-logs/'
                            ]
                        )

                        archiveArtifacts(
                            artifacts: SYSTEM_PACKAGE + ', test_results.xml',
                            fingerprint: true
                        )

                        cleanWs()
                    }
                }
            }
        }

    }

    //--------------------------------------------------------------------------
    post {
        always {
            do_notify_bitbucket()
        }
    }

}
