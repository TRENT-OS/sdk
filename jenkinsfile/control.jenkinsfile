//------------------------------------------------------------------------------
//
// SDK Jenkins Pipeline Control Script
//
// Copyright (C) 2020-2021, HENSOLDT Cyber GmbH
//
//------------------------------------------------------------------------------

// Global variables defined with 'def' cannot be accessed in methods due to
// different scoping. Without 'def', they can be accessed - however, that is bad
// practice. Using 'def' and the '@groovy.transform.Field' annotation is the
// best option. For details see https://stackoverflow.com/questions/50571316

@groovy.transform.Field
def final NODE_LABEL_CONTROL = 'pipeline-control'

@groovy.transform.Field
def final NODE_LABEL_BUILD = 'build'

@groovy.transform.Field
def final NODE_LABEL_PUBLISH_DOC = 'publish_doc'

@groovy.transform.Field
def final STASH_SDK_SCRIPT = 'sdk_script'

@groovy.transform.Field
def final STASH_SDK_DOC = 'sdk_doc'

@groovy.transform.Field
def final DEV_SDK_PACKAGE = 'dev-sdk-package.tar.bz2'

@groovy.transform.Field
def final SDK_PACKAGE = 'sdk-package.tar.bz2'

@groovy.transform.Field
def final SYSTEM_PACKAGE = 'system-package.tar.bz2'

@groovy.transform.Field
def final TEST_RESULT_PACKAGE = 'test-result-package.tar.bz2'

@groovy.transform.Field
def final SYSTEM_PACKAGES = 'system-packages.tar.bz2'

@groovy.transform.Field
def final GENERIC_PROJECT_BUILDER_JOB = 'generic_jobs/generic_pipeline_sandbox'

// Test systems, list is read from config
@groovy.transform.Field
def SYSTEM_CONFIGS = []

//------------------------------------------------------------------------------
// Docker
//
// Notes:
// * bind the localtime to docker container to avoid problems of gaps between
//   the localtime of the container and the host.
// * add user to group "stack" (1001) in order to grant usage of Haskell stack
//   in the docker image
//
// ToDo
// * why are sudo rights needed in the test container
//

// This helper function must be annotated with "@NonCPS", otherwise jenkins
// fails with some unknown internal error. This seems to be related to passing a
// list in the parameter 'args'. Details are unclear, the logs just say:
//
//      psCallableInvocation{
//        methodName=makeDockerAgentCfg,
//        call=com.cloudbees.groovy.cps.impl.CpsFunction@6e025e85,
//        receiver=WorkflowScript@603646a9,
//        arguments=[...]
//      }
//      Finished: FAILURE
//
@NonCPS
def makeDockerAgentCfg(server, credentialsId, image, args)
{
    def m = (server =~ '(?:(.*)://)?([^/:]*)(?::([1-9][0-9]*))?(?:/(.*))?')
    if (!m.matches()) {
        throw new Exception("invalid server: ${server}")
    }
    def protocol = m.group(1) ?: "https"
    def domain = m.group(2)
    def port = m.group(3) ? Integer.parseInt(m.group(3)) : null
    def path = m.group(4)

    def registry = domain + ( port ? ":${port}" : '')

    return [
        registryUrl: "${protocol}://${registry}",
        registryCredentialsId: credentialsId,
        image: registry + (path ? "/${path}" : '') + "/${image}",
        args: (args instanceof List) ? args.join(' ') : args,
    ]
}


@groovy.transform.Field
def final DOCKER_BUILD_ENV = makeDockerAgentCfg(
        'hc-docker:5000',
        null, // no credentials needed
        'trentos_build:20210503',
        [
            '-v /etc/localtime:/etc/localtime:ro',
            '--group-add=stack',
        ]
    )

@groovy.transform.Field
def final DOCKER_TEST_ENV = makeDockerAgentCfg(
        'hc-docker:5000',
        null, // no credentials needed
        'trentos_test:20211217',
        [
            '-v /home/jenkins/.ssh/:/home/jenkins/.ssh:ro',
            '-v /etc/localtime:/etc/localtime:ro',
            '--network=bridge',
            '--cap-add=NET_ADMIN',
            '--cap-add=NET_RAW',
            '--device=/dev/net/tun',
            '--group-add=sudo'
        ]
    )


//------------------------------------------------------------------------------
// System context
class SystemCtx {
    // WARNING: the flags are used in jenkinsfile-generic also, so ensure the
    //          values are always in sync.
    static final FLAG_BUILD      = 1 << 0
    static final FLAG_TEST       = 1 << 1
    // For demos included in the SDK package, CI will checkout them from their
    // default repo or use that the SDK package contains at the given location.
    static final FLAG_SDK_DEMO   = 1 << 2

    static final KNOWN_DEMOS = [
        'demo_hello_world',
        'demo_iot_app',
        'demo_iot_app_imx6',
        'demo_iot_app_rpi3',
        'demo_network_filter',
        'demo_tls_api',
    ]

    String      systemName   // Name of the system to build.
    Map         platforms    // List of supported platforms.
    Map         params       // Parameters

    //--------------------------------------------------------------------------
    public SystemCtx(systemName, platforms, params)
    {
        this.systemName = systemName
        this.platforms = platforms
        this.params = params ?: [:]

        // ensure proper defaults exists
        this.params.putIfAbsent('flags', 0)
        this.params.putIfAbsent('testScript', "${systemName}.py")
        this.params.putIfAbsent('testSystem', "ss/${systemName}")

        // Check demos against the well-known list. Adding new demos to the SDK
        // package could have side effects that should be well unterstood.
        if (this.is_demo() && !(systemName in this.KNOWN_DEMOS)) {
            throw new Exception("unknown demo: ${systemName}")
        }
    }

    //--------------------------------------------------------------------------
    @NonCPS
    public boolean is_demo()
    {
        return (0 != (this.params['flags'] & this.FLAG_SDK_DEMO))
    }
}


//--------------------------------------------------------------------------
def yaml_parse_flags(arg)
{
    def flags = 0

    if (null == arg) {
        // do nothing

    } else if (arg instanceof List) {
        for (e in arg) {
            flags |= yaml_parse_flags(e)
        }

    } else if (arg instanceof String) {
        flags = [
            'BUILD':    SystemCtx.FLAG_BUILD,
            'TEST':     SystemCtx.FLAG_TEST,
            'SDK_DEMO': SystemCtx.FLAG_SDK_DEMO,
        ].get(arg.toUpperCase())
        if (!flags) {
            error("unknown flag: ${arg}")
        }

    } else {
        error("unsupported flag argument ${arg.getClass()}: ${arg}")
    }

    return flags
}


//--------------------------------------------------------------------------
def yaml_parse_params(arg)
{
    def params = []

    if (null == arg) {
        // do nothing

    } else if (arg instanceof List) {
        for (e in arg) {
            params.addAll(yaml_parse_params(e))
        }

    } else if (arg instanceof String) {
        params.add(arg)

    } else {
        error("unsupported parameter argument ${arg.getClass()}: ${arg}")
    }

    return params
}


//--------------------------------------------------------------------------
def yaml_parse_platform_params(arg)
{
    def params = [:]

    if (null == arg) {
        // do nothing

    } else if (arg instanceof Map) {
        for (e in arg) {
            switch(e.key) {
                case 'addFlags':
                    params.putAt(e.key, yaml_parse_flags(e.value))
                    break
                case 'buildParams':
                case 'testParams':
                    params.putAt(e.key, yaml_parse_params(e.value))
                    break
                default:
                    error("unknown platform attribute: ${e.key}")
            }
        }

    } else {
        error("unsupported platform parameter argument ${arg.getClass()}: ${arg}")
    }

    return params
}


//--------------------------------------------------------------------------
def yaml_parse_platforms(arg)
{
    def platforms = [:]

    if (null == arg) {
        // do nothing

    } else if (arg instanceof List) {
        for (e in arg) {
            platforms.putAll(yaml_parse_platforms(e))
        }

    } else if (arg instanceof Map) {
        for (e in arg) {
            platforms.putAt(e.key, yaml_parse_platform_params(e.value))
        }

    } else if (arg instanceof String) {
        platforms.putAt(arg, null)

    } else {
        error("unsupported platform argument ${arg.getClass()}: ${arg}")
    }

    return platforms
}


//------------------------------------------------------------------------------
def process_yaml_config(yaml_file, branch)
{
    def cfg = readYaml([file: yaml_file])

    SYSTEM_CONFIGS = []
    for (system in cfg) {
        def systemName = system.key

        if (!(systemName ==~ /[a-zA-Z_][a-zA-Z0-9_\-]*/ )) {
            error("invalid test system name: ${systemName}")
        }

        if (SYSTEM_CONFIGS.any { it.systemName == systemName }) {
            error("duplicate test system: ${systemName}")
        }

        if (!(system.value instanceof Map)) {
            error("system with invalid data: ${systemName}")
        }

        def platforms = [:]
        def params = [flags: 0]
        for (e in system.value) {
            switch (e.key) {
                case 'flags':
                    params.putAt(e.key, yaml_parse_flags(e.value))
                    break
                case 'platforms':
                    platforms = yaml_parse_platforms(e.value)
                    break
                case 'testSystem':
                case 'testScript':
                    if (!(e.value instanceof String))
                        error("testScript invalid for system: ${systemName}")
                    params.putAt(e.key, e.value)
                    break
                case 'buildParams':
                case 'testParams':
                    params.putAt(e.key, yaml_parse_params(e.value))
                    break
                default:
                    error("system ${systemName} with unsupported attribute: ${attr}")
            }
        }

        systemCtx = new SystemCtx(systemName, platforms, params)

        if (systemCtx.is_demo()) {
            // SDK demos are always build from the sources in SDK package,
            // thus we check them out here already and then overwrite the
            // 'testSystem' parameter with the location. The build job
            // knows that for FLAG_SDK_DEMO it's a folder and not a repo.
            def folder = "demos/${systemName}"
            do_checkout(systemCtx.params['testSystem'], branch, "src/${folder}")
            systemCtx.params['testSystem'] = folder
        }

        SYSTEM_CONFIGS.add(systemCtx)
    }
}


//------------------------------------------------------------------------------
def print_step_info(name)
{
    println("######## ${name}")
}


//------------------------------------------------------------------------------
def do_notify_bitbucket()
{
    // the StashNotifier requires to run in a node block, which should not be
    // necessary technically. See also the open issue issue at
    // https://github.com/jenkinsci/stashnotifier-plugin/issues/234

    if (env.NODE_NAME)
    {
        notifyBitbucket()
    }
    else
    {
        // If we don't specify any node here explicitly, it will not run on the
        // master node even if it is free, because the master is reserved
        // exclusively for bound jobs. If all other executors are busy, the
        // whole job will stuck just for sending a notification. Thus we use the
        // master node for the notification.
        node(label: NODE_LABEL_CONTROL) { notifyBitbucket() }
    }
}


//------------------------------------------------------------------------------
def do_stash(name, file_list)
{
    println("stashing to ${name}")
    stash([
        name: name,
        allowEmpty: true,
        includes: file_list.join(',')
    ])
}


//------------------------------------------------------------------------------
def save_current_job_log(
    name
) {
    // Get the current job's log up to now. One day we should find a nicer way
    // for this than downloading it, because that requires read access for
    // anonymous users to the Jenkins GUI. Accessing the log though the builds's
    // RunWrapper object is not possible, because nothing is exposed there. The
    // only option would be via rawBuild(), but this method must be whitelisted
    // for usage in groovy pipelines then.

    run_app(
        'wget',
        [
            '-q',
            '--no-check-certificate',
            "-O ${name}",
            "${BUILD_URL}consoleText"
        ]
    )
}


//------------------------------------------------------------------------------
def get_build_relative_url(build)
{
    // getAbsoluteUrl() is deprecated and generally regarded as a bad idea for
    // generating HTML page content. This workaround avoids accessing the raw
    // build, which can't be done by scripts by default

    fpn = build.getFullProjectName().replace('/', '/job/')
    return "/job/${fpn}/${build.getNumber()}"

}


//------------------------------------------------------------------------------
def get_result_ball_img_url(result)
{
    def img = [
        'SUCCESS':  'green.gif', // there is no png
        'UNSTABLE': 'yellow.png',
        'FAILURE':  'red.png',
        'ABORTED':  'aborted.png'
    ].getOrDefault(result, 'help.png')

    return "${Jenkins.RESOURCE_PATH}/images/16x16/${img}"
}


//------------------------------------------------------------------------------
def run_app(
    application,
    param_array = null
) {
    def cmdLine = application

    if (param_array)
    {
        cmdLine += " ${param_array.join(' ')}"
    }

    try
    {
        sh(cmdLine)
    }
    catch (Exception e)
    {
        println("Exception running command: ${e}")
        throw e
    }
}


//------------------------------------------------------------------------------
def run_shell_script(
    script,
    param_array = null
) {
    run_app(script, param_array)
}


//------------------------------------------------------------------------------
def archive_as_tar_bz2(name, files = null)
{
    def params = [
        '-c',
        '-j',
        "-f ${name}",
        '--ignore-failed-read',
        '--sort=name',
        '--numeric-owner',
        '--owner=0',
        '--group=0',
    ]

    if (files) {
        params += files
    }

    run_app('tar', params)
    archiveArtifacts(artifacts: name, fingerprint: true)
}


//------------------------------------------------------------------------------
def do_git_checkout(
    repo,
    branch,
    folder = NULL
) {
    println("checkout ${repo}@${branch}" +
            (folder ? " into ${folder}" : '') + ' ...')

    try
    {
        def scm_cfg = scm.userRemoteConfigs[0]

        // use project URL to build repo URL
        def m = (scm_cfg.url =~ '(.*)://([^/]*)(?:/(.*))?')
        if (!m.matches()) {
            throw new Exception("could not parse url: ${url}")
        }
        def repo_url = "${m.group(1)}://${m.group(2)}/${repo}.git"

        def scmVars = checkout([
                    poll: false,
                    changelog: false,
                    scm: [
                        $class: 'GitSCM',
                        branches: [
                            [name: branch]
                        ],
                        doGenerateSubmoduleConfigurations: false,
                        extensions: [
                            [
                                $class: 'RelativeTargetDirectory',
                                relativeTargetDir: (folder?:'.')
                            ],

                            [
                                $class: 'SubmoduleOption',
                                disableSubmodules: false,
                                recursiveSubmodules: true,
                                trackingSubmodules: false,
                                parentCredentials: true,
                                // parallel checkouts speed up things, but too
                                // many threads (from too man parallel jobs)
                                // will eventually overload the GIT server and
                                // we get failures due to timeouts. We've seen
                                // this happening with 8 threads, so try 4 now.
                                threads: 4
                            ]
                        ],
                        userRemoteConfigs: [
                            [
                                credentialsId: scm_cfg.credentialsId,
                                url: repo_url
                            ]
                        ]
                    ]
                ])

        // clean up some strange folders jenkins creates for an unknown reason
        if (folder) { run_app('rmdir', ["${folder}@tmp"]) }

        return scmVars
    }
    catch (Exception e)
    {
        println "Exception: ${e}"
        return null
    }
}


//------------------------------------------------------------------------------
def do_checkout(
    repo,
    branch,
    dir = '.'
) {
    // if there is no branch with the give name, the fallback is 'integration'
    // and then 'master'.
    def branches = [branch]
    if ('master' != branch) {
        if ('integration' != branch) {
            branches.add('integration')
        }
        branches.add('master')
    }

    for (try_branch in branches)
    {
        if (do_git_checkout(repo, try_branch, dir))
        {
            return
        }
    }

    error("checkout error for ${repo}, no branches: ${branches.join(', ')}")
}


//------------------------------------------------------------------------------
def makeParamStr(Object... args)
{
    def paramList = []
    for (arg in args) {
        if (!arg) {
            // ignore null elements
        } else if (arg instanceof String) {
            paramList.add(arg)
        } else if (arg instanceof List) {
            list = arg.flatten()
            list.removeAll([null])
            paramList.addAll(list)
        } else {
            error("Invalid parameter object: " + arg);
            // ignore
        }
    }

    return paramList.join(' ')
}


//------------------------------------------------------------------------------
def execute_build(ctx, stage_ctx)
{
    def jobBuild = build(
        job: GENERIC_PROJECT_BUILDER_JOB,
        wait: true,   // block call until finished
        propagate: false, // don't throw exception on error
        parameters: [
            string(
                name:  'BRANCH_OR_COMMIT',
                value: ctx.branch ?: ''
            ),
            string(
                name: 'PARAMS_JSON',
                value: writeJSON([
                    returnText: true,
                    json: [
                        'PLATFORM': stage_ctx.get('platform'),
                        'TEST_SYSTEM': stage_ctx.get('testSystem'),
                        'BUILD_PARAMS': stage_ctx.get('buildParams'),
                        'TEST_SCRIPT': stage_ctx.get('testScript'),
                        'TEST_PARAMS': stage_ctx.get('testParams'),
                        'SDK_SOURCE': "job://${currentBuild.fullProjectName}:${currentBuild.id}",
                        'DOCKER_BUILD_ENV': DOCKER_BUILD_ENV,
                        'DOCKER_TEST_ENV': DOCKER_TEST_ENV,
                    ].findAll{ !(it.value in [null, '']) }
                ])
            ),
        ]
    )

    // If we arrive here, the job has finished. Since propagate=false is set,
    // unsuccessful builds don't throw an exception and we can deal with this
    // manually. Even failed builds may have produced artifacts we want to save.
    stage_ctx.build = jobBuild
    def idx = ctx.cnt - ctx.running.decrementAndGet()
    def result = jobBuild.getResult()
    def duration = jobBuild.getDurationString()

    def operations = []
    def flags = stage_ctx.getOrDefault('flags', 0)
    if (flags & SystemCtx.FLAG_BUILD) { operations += ['build'] }
    if (flags & SystemCtx.FLAG_TEST) { operations += ['test'] }
    if (flags & SystemCtx.FLAG_SDK_DEMO) { operations += ['demo'] }
    def op_str = operations ? operations.join(', ') : ''

    // propagate the result to the current state and build result, but catch the
    // exception so we can continue
    def msg = "job ${idx}/${ctx.cnt}: ${result} for " +
              "${stage_ctx.test_ctx.systemName}, " +
              "${stage_ctx.platform}, ${duration}  [${op_str}]"
    if ('SUCCESS' == result) {
        println(msg)
    } else if ('UNSTABLE' == result) {
        unstable(msg) // will also set buildResult to UNSTABLE
    } else { // anything else (FAILURE, ABORTED ...) is considered an error
        catchError(
            buildResult: 'UNSTABLE',
            stageResult: result // propagate sub-job result
        ) {
            error(msg)
        }
    }

    ctx.summary.appendText(
        "${stage_ctx.test_ctx.systemName}, ${stage_ctx.platform}" +
        " <a href=\"${get_build_relative_url(jobBuild)}\">#${jobBuild.getNumber()}</a>" +
        " <img src=\"${get_result_ball_img_url(result)}\">" +
        "${duration} [${op_str}]<br>",
        false)

    // When CI is under heavy load, no free executor could be available to run
    // the artifact copy from the child job. In the worst case the child job
    // already got deleted. We could extend the time before the job is deleted,
    // but this may overload CI also, because the workspaces eat the disk space.
    // Better solution is running the copy job on a dedicated executor, which
    // exists on the master
    node(label: NODE_LABEL_CONTROL)
    {
        cleanWs()

        catchError(buildResult: 'UNSTABLE', stageResult: 'FAILURE')
        {
            copyArtifacts(
                projectName: jobBuild.getFullProjectName(),
                // need to ensure selector is a string
                selector: specific("${jobBuild.getNumber()}"),
                filter: [
                    SYSTEM_PACKAGE,
                    TEST_RESULT_PACKAGE
                ].join(',')
            )
        }

        do_stash(
            stage_ctx.name,
            [
                SYSTEM_PACKAGE,
                TEST_RESULT_PACKAGE
            ]
        )

        cleanWs()
    }

}


//------------------------------------------------------------------------------
def do_jobs_for_test_systems(branch, testConfigs)
{
    def summary = manager.createSummary("orange-square.png")
    summary.appendText('<hr>')

    def jobStages = []
    for (test_ctx in testConfigs) {

        def baseFlags = test_ctx.params?.get('flags') ?: 0
        def testSystem = test_ctx.params?.get('testSystem')

        if (!testSystem) {
            // Test system is initialized to 'null' in the constructor if a
            // non-default repo is specified for an SDK demo, which is not
            // supported.
            error("SDK demo must use default repo: ${test_ctx.systemName}")
            continue // this is not a blocker for other tests
        }

        for (plat in test_ctx.platforms) {

            def platName = plat.key
            def platParams = plat.value
            def flags = baseFlags | (platParams?.get('addFlags') ?: 0)
            def isBuild = (flags & SystemCtx.FLAG_BUILD)
            def isTest = (flags & SystemCtx.FLAG_TEST)

            // Currently, a test always requires a build. But in the future,
            // testing an existing system might also be supported.
            if (!isBuild) {
                error("no built requested for ${test_ctx.systemName}")
                continue
            }

            jobStages.add([
                name:        "${platName}-${test_ctx.systemName}",
                test_ctx:    test_ctx,
                platform:    platName,
                flags:       flags,

                // get demos from package and test systems from repo
                testSystem:  ((flags & SystemCtx.FLAG_SDK_DEMO) ? 'pkg' : 'repo') +
                             '://' + testSystem,

                // put platform params after test_ctx params
                buildParams: makeParamStr(
                                test_ctx.params?.get('buildParams'),
                                platParams?.get('buildParams')),

                // platform setting takes preference over test_ctx setting
                testScript:  !isTest ? null :
                             platParams?.get('testScript') ?:
                             test_ctx.params?.get('testScript') ?:
                             null,

                // put platform params after test_ctx params
                testParams:  !isTest ? null :
                             makeParamStr(
                                test_ctx.params?.get('testParams'),
                                platParams?.get('testParams')),

                build:       null // will be set once there is a build
            ])
        }
    }

    def num_jobs = jobStages.size()
    def sub_jobs_ctx = [
        summary:   summary,
        branch:    branch,
        cnt:       num_jobs,
        running:   new java.util.concurrent.atomic.AtomicInteger(num_jobs),
    ]

    def build_start = new Date()

    catchError(buildResult: 'UNSTABLE', stageResult: 'FAILURE')
    {
        // we don't need an executor to start the jobs and wait for them to
        // finish
        //
        //  parallel
        //      firstBranch:  { /* do something */ },
        //      secondBranch: { /* do something */ },
        //      failFast: true|false // terminate all upon any one failing

        parallel(
            // Create a map, where each key is an arbitrary name and the value
            // is a closure with the code that will be executed in parallel
            // (potentially distributed) jobs.
            jobStages.collectEntries { stage_ctx ->
                [
                    ( stage_ctx.name ):
                    { ->
                        stage(stage_ctx.name) {
                            execute_build(sub_jobs_ctx, stage_ctx)
                        }
                    }
                ]
            }
        )
    }

    duration = groovy.time.TimeCategory.minus(new Date(), build_start)
    def duration_msg = "all system build/test stages took ${duration}"
    println(duration_msg)
    summary.appendText("<hr>${duration_msg}", false)

    // builds are done, now collect the results and artifacts. This needs a
    // workspace, so we have to allocate a node

    def was_build_error = false

    // Actually, this is a pipeline control an data management job that should
    // run on NODE_LABEL_CONTROL. However, we can't do the work purely with
    // Jenkins plugin, shell commands are needed to to create a bz2 archive.
    // Since there is no guarantee any shell tools exist (especially not in the
    // Jenkins master container) and we don't support docker-in-docker yet, we
    // have to use a build slave here. Actually, maything that needs tools
    // should run in a docker container (may busybox?) also.
    node(label: NODE_LABEL_BUILD) {
        stage('process_results') {

            cleanWs()

            def tar_list = []

            jobStages.eachWithIndex { stage_ctx, idx ->

                println("processing ${idx+1}/${jobStages.size()}: ${stage_ctx.name}")

                dir(stage_ctx.name)
                {
                    // there might be no stash if something failed earlier
                    catchError(buildResult: 'UNSTABLE', stageResult: 'FAILURE')
                    {
                        unstash(stage_ctx.name)
                    }

                    if (fileExists(SYSTEM_PACKAGE)) {
                        dir('system') {
                            run_app('tar', ["-xf ../${SYSTEM_PACKAGE}"])
                        }
                        tar_list.add("${stage_ctx.name}/system/")
                    }
                    if (fileExists(TEST_RESULT_PACKAGE)) {
                        dir('test-result') {
                            run_app('tar', ["-xf ../${TEST_RESULT_PACKAGE}"])
                            if (fileExists('test_results.xml')) {
                                // In some cases the processing fails, e.g.
                                // when there are zero test results in the file
                                // because there was a platform init problem
                                // already.
                                catchError(buildResult: 'UNSTABLE', stageResult: 'FAILURE')
                                {
                                    // TODO: Support different platforms in junit
                                    //       result processing. Currently seeing
                                    //       the same test cases multiple times is
                                    //       likely messing up the analysis.
                                    junit('test_results.xml')
                                }
                            }
                        }
                        tar_list.add("${stage_ctx.name}/test-result/")
                    }
                }

                def pkg_build = stage_ctx.build
                was_build_error |= (!pkg_build) ||
                                   (pkg_build.getResult() in ['FAILURE','ABORTED'])
            }

            save_current_job_log('build.log')

            // Create a package of all files and make is available as artifact.
            archive_as_tar_bz2(SYSTEM_PACKAGES, ['build.log'] + tar_list)

            cleanWs()

        }
    }

    if (was_build_error)
    {
        error('stage failed: run test systems')
    }
}


//------------------------------------------------------------------------------
pipeline {

    agent none

    options {
        buildDiscarder(logRotator(numToKeepStr: '10'))
        skipDefaultCheckout()
        // must prefix with '/' explicitly to make this an 'absolute' name
        copyArtifactPermission("/${GENERIC_PROJECT_BUILDER_JOB}");
    }

    stages {

        //----------------------------------------------------------------------
        stage('Build SDK') {

            agent { label NODE_LABEL_BUILD }

            stages {

                //--------------------------------------------------------------
                stage('checkout') {
                    steps {
                        print_step_info(env.STAGE_NAME)
                        cleanWs()
                        checkout([
                            $class: 'GitSCM',
                            branches: scm.branches,
                            doGenerateSubmoduleConfigurations: false,
                            extensions: [
                                [
                                    $class: 'RelativeTargetDirectory',
                                    relativeTargetDir: 'scm-src'
                                ],
                                [
                                    $class: 'SubmoduleOption',
                                    disableSubmodules: false,
                                    recursiveSubmodules: true,
                                    trackingSubmodules: false,
                                    parentCredentials: true,
                                    threads: 4,
                                ]
                            ],
                            userRemoteConfigs: scm.userRemoteConfigs
                        ])
                        process_yaml_config('scm-src/test-cfg.yaml', env.BRANCH_NAME)
                        do_notify_bitbucket()
                    }
                }

                //--------------------------------------------------------------
                stage('package') {
                    agent {
                        docker {
                            reuseNode true
                            alwaysPull true
                            registryUrl DOCKER_BUILD_ENV.registryUrl
                            registryCredentialsId DOCKER_BUILD_ENV.registryCredentialsId
                            image DOCKER_BUILD_ENV.image
                            args DOCKER_BUILD_ENV.args
                        }
                    }
                    steps {
                        print_step_info(env.STAGE_NAME)
                        // mode=package, output into folder 'sdk-package'
                        run_shell_script(
                            'scm-src/build-sdk.sh', ['package', 'sdk-package']
                        )
                    }
                }

                //--------------------------------------------------------------
                stage('archive') {
                    steps {
                        print_step_info(env.STAGE_NAME)
                        archiveArtifacts([
                            artifacts: [
                                DEV_SDK_PACKAGE,
                                SDK_PACKAGE,
                                'sdk-package/version.info'
                            ].join(','),
                            fingerprint: true
                        ])

                        do_stash(STASH_SDK_SCRIPT, ['scm-src/build-sdk.sh'])

                        do_stash(
                            STASH_SDK_DOC,
                            [
                                'scm-src/publish_doc.sh',
                                'sdk-package/pkg/doc/'
                            ]
                        )
                    }
                }

                //--------------------------------------------------------------
                stage('publish_docs') {
                    agent { label NODE_LABEL_PUBLISH_DOC }
                    when {
                        beforeAgent true
                        anyOf {
                            branch 'master'
                            branch 'integration'
                        }
                    }
                    steps {
                        print_step_info(env.STAGE_NAME)
                        cleanWs()
                        unstash(STASH_SDK_DOC)
                        run_shell_script('scm-src/publish_doc.sh', [env.BRANCH_NAME])
                    }
                }

                //--------------------------------------------------------------
                stage('cleanup') {
                    steps {
                        print_step_info(env.STAGE_NAME)
                        cleanWs()
                    }
                }
            }
        }

        //----------------------------------------------------------------------
        stage('Test SDK') {

            agent { label NODE_LABEL_BUILD }

            stages {
                //--------------------------------------------------------------
                stage('prepare') {
                    steps {
                        print_step_info(env.STAGE_NAME)
                        cleanWs()
                        unstash(STASH_SDK_SCRIPT)
                        copyArtifacts(
                            projectName: JOB_NAME,
                            selector: specific("${BUILD_NUMBER}"), // must be a string
                            filter: DEV_SDK_PACKAGE
                        )
                        // Extract the DEV_SDK_PACKAGE into the subfolder 'pkg',
                        // the name is hard-coded in the SDK build script.
                        run_app('mkdir', ['-p', 'pkg'])
                        run_app('tar', ["-xf ${DEV_SDK_PACKAGE}", '-C pkg'])
                    }
                }

                //--------------------------------------------------------------
                stage('astyle') {
                    agent {
                        docker {
                            reuseNode true
                            alwaysPull true
                            registryUrl DOCKER_BUILD_ENV.registryUrl
                            registryCredentialsId DOCKER_BUILD_ENV.registryCredentialsId
                            image DOCKER_BUILD_ENV.image
                            args DOCKER_BUILD_ENV.args
                        }
                    }
                    steps {
                        print_step_info(env.STAGE_NAME)
                        // Continue with the SDK package build even on style
                        // errors, but mark the stage and the build as failed
                        // already.
                        catchError(buildResult: 'FAILURE', stageResult: 'FAILURE') {
                            run_shell_script('pkg/astyle_check_sdk.sh')
                        }
                    }
                }

                //--------------------------------------------------------------
                stage('unit_test') {
                    agent {
                        docker {
                            reuseNode true
                            alwaysPull true
                            registryUrl DOCKER_TEST_ENV.registryUrl
                            registryCredentialsId DOCKER_TEST_ENV.registryCredentialsId
                            image DOCKER_TEST_ENV.image
                            args DOCKER_TEST_ENV.args
                        }
                    }
                    steps {
                        print_step_info env.STAGE_NAME
                        catchError(buildResult: 'UNSTABLE', stageResult: 'FAILURE') {
                            run_shell_script(
                                'scm-src/build-sdk.sh',
                                [
                                    'run-unit-tests', // mode
                                    '.' // base dir
                                ]
                            )
                        }
                    }
                }

                //--------------------------------------------------------------
                stage('sanity_check') {
                    // Do a quick sanity test for the SDK package by building
                    // the demo Hello World for zynq7000. Only if it works, the
                    // time consuming builds and tests of all systems are done.
                    agent {
                        docker {
                            reuseNode true
                            alwaysPull true
                            registryUrl DOCKER_BUILD_ENV.registryUrl
                            registryCredentialsId DOCKER_BUILD_ENV.registryCredentialsId
                            image DOCKER_BUILD_ENV.image
                            args DOCKER_BUILD_ENV.args
                        }
                    }
                    steps {
                        print_step_info(env.STAGE_NAME)
                        run_shell_script(
                            'scm-src/build-sdk.sh',
                            [
                                'sanity-check', // mode
                                '.' // base dir
                            ]
                        )
                    }
                }

                //--------------------------------------------------------------
                stage('cleanup') {
                    steps {
                        print_step_info env.STAGE_NAME
                        cleanWs()
                    }
                }

            }
        }

        //----------------------------------------------------------------------
        stage('Test Systems') {
            steps {
                print_step_info(env.STAGE_NAME)
                do_jobs_for_test_systems(env.BRANCH_NAME, SYSTEM_CONFIGS)
            }
        }
    }

    //--------------------------------------------------------------------------
    post {
        always {
            do_notify_bitbucket()
        }
    }
}
